<!DOCTYPE html>
<html lang="en">
<title>GenAI and the GPT magic</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="./web_files/w3.css">
<link rel="stylesheet" href="./web_files/w3-theme-black.css">
<link rel="stylesheet" href="./web_files/css?family=Roboto">
<link rel="stylesheet" href="./web_files//font-awesome.min.css">
<style>
html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif;}
.w3-sidebar {
  z-index: 3;
  width: 250px;
  top: 43px;
  bottom: 0;
  height: inherit;
}
</style>
<body>

<!-- Navbar -->
<div class="w3-top">
  <div class="w3-bar w3-theme w3-top w3-left-align w3-large">
    <a class="w3-bar-item w3-button w3-right w3-hide-large w3-hover-white w3-large w3-theme-l1" href="javascript:void(0)" onclick="w3_open()"><i class="fa fa-bars"></i></a>
    <a href="#Intro" class="w3-bar-item w3-button w3-theme-l1">MIBE: Information Systems for Managers</a>
    <a href="#Module1" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 1</a>
    <a href="#Module2" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 2</a>
    <a href="#Module3" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 3</a>
    <a href="#Module4" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 4</a>
    <a href="#Module5" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 5</a>
    <a href="#Module6" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 6</a>
    <a href="#Module7" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Module 7</a>
  </div>
</div>

<!-- Sidebar -->
<nav class="w3-sidebar w3-bar-block w3-collapse w3-large w3-theme-l5 w3-animate-left" id="mySidebar">
  <a href="javascript:void(0)" onclick="w3_close()" class="w3-right w3-xlarge w3-padding-large w3-hover-black w3-hide-large" title="Close Menu">
    <i class="fa fa-remove"></i>
  </a>
  <h4 class="w3-bar-item"><b>Menu</b></h4>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Intro">Introduction</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module1">Module 1</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module2">Module 2</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module3">Module 3</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module4">Module 4</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module5">Module 5</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module6">Module 6</a>
  <a class="w3-bar-item w3-button w3-hover-black" href="./index.html#Module7">Module 7</a>
</nav>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- Main content: shift it to the right by 250 pixels when the sidebar is visible -->
<div class="w3-main" style="margin-left:250px">

    <a name="Intro"></a>
    <div class="w3-row w3-padding-64">
    <div class="w3-twothird w3-container">
      <h1 class="w3-text-teal">GenAI and the GPT magic</h1>
        <p>
          This page provides links and access to all the materials and activities you need to play along and understand how generative AI works</b>
        </p>
      <h3 class="w3-text-teal">Data and data preparation</h3>
        <p>
        	<ul>
          <li>
          	Activity 1: Visit <a href="https://chatgpt.com/" target="new">ChatGPT</a>. Type something in the chat and think about what is happening. Can you explain what is going on in the background? How does this helpful, truthful, harmless assistant work?
          </li>
          <li>
            High quality Web text, like the <a href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1" target="new">FineWeb</a> dataset, is a key ingredient of machine learning models. FineWeb is aa large-scale (15-trillion tokens, 44TB disk space) dataset for Large Language Model pre-training.
          </li>   
          <li>
            Activity 2: Visit the <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb" target="new">FineWeb</a> dataset page on the <a href="https://huggingface.co/" target="new">Hugging Face</a> AI community website and explore it. Get a feel for the type of text that makes up the Fine Web dataset. 
          </li>
           <li>
            A training dataset is a one-dimensional sequence of text, like this <a href="https://dds.cct.lsu.edu/wwwgp/genai-activity/data-files/fine-web-200.txt" target="new">sample of 200 documents from the FineWeb</a> dataset. This one-dimensional sequence of text must have some representation. Here you can see a UTF-8 representation of the <a href="https://dds.cct.lsu.edu/wwwgp/genai-activity/data-files/fine-web-200-hex-only.txt" target="new">sample of 200 documents from the FineWeb</a> in the previous dataset.
          </li>
      </ul>
        </p>
      <h3 class="w3-text-teal">Tokenization</h3>
        <p>
         <ul>
           <li>
            Activity 3: Visit <a href="https://tiktokenizer.vercel.app/?model=cl100k_base" target="new">TikTokenizer</a>, select a model and explore tokenization. Grab chunks of the <a href="https://dds.cct.lsu.edu/wwwgp/genai-activity/data-files/fine-web-200.txt" target="new">sample of 200 documents from the FineWeb</a> and paste them into the TikTokenizer to experiment with tokenization. Changing model you can see different tokenization vocabularies.
          </li> 
      </ul>
         </p>
      <h3 class="w3-text-teal">Pre-training and the transformer</h3>
        <p>
          <ul>
            <li>
              Video 1: Here you can get a basic intuition for how a neural network learns to performs the basic task of <a href="https://www.3blue1brown.com/lessons/neural-networks" target="new">recognizing handwritten digits</a>. Recognizing handwritten digits was the first breakthrough machine learning task in deep learning.
            </li>
            <li>
              Video 2: Here you can get a basic intuition for the "learning algorithm" known as <a href="https://www.3blue1brown.com/lessons/backpropagation" target="new">backpropagation</a>.
            </li>
            <li>
              Video 3: Here you can get a basic intuition for the <a href="https://www.3blue1brown.com/lessons/gpt" target="new">General Pretrained Transformer</a> architecture that has revolutionized machine learning into generative AI.
            </li>
            <li>
              Video 4: You could try to train your own transformer, but if you don't have time, what this video of <a href="https://www.youtube.com/watch?v=7xTGNNLPyMI&t=2000s" target="new">Andrej Karpathy reproducing GPT2</a>.
            </li>
           <li>
            Activity 5: To get a sense of some characteristics and limitations of language models, we can experiment with GPT2. Download <a href="https://dds.cct.lsu.edu/wwwgp/genai-activity/data-files/GPT2-code.rtf" target="new">the code</a> we need and paste it into a cell at <a href="https://colab.research.google.com/" target="new">Google Colab</a>. If all goes well, you should be able to change the prompt between the quotes <i>"This is the beginning of some text that "</i> and play with parameters such as temperature and max_length.
          </li> 
            <li>
              Video 5: A critical element of the transformer is <a href="https://www.3blue1brown.com/lessons/attention" target="new">attention</a>. Using the attention mechanism the transformer updates the embedding of each token to encode not only it's original meaning, but an increasing amount of contextual information gleaned from preceding tokens in the context window.
            </li>
            <li>
              Video 6: A final element of the transformer is <a href="https://www.3blue1brown.com/lessons/mlp" target="new">memory</a>. This is where the "knowldege of the world" lives in the language model - a component known as the Multilayer Perceptron (MLP).
            </li>
             <li>
              Activity 6: Visit <a href="https://hyperbolic.xyz/" target="new">Hyperbolic</a> and experiment with a base model like LLAMA-3.1-405B-BASE. Try some prompts the model can complete. Then try asking some questions (e.g., who is Tom Cruise?). Then complicate things and ask the model to perform simple math. Or ask about made up things (e.g., who is Tanfregato Giovanni) and current events (e.g., the score of a recent game). Why is the model behaving as it is? What about on creative tasks, like the best places to visit in Rome? 
            </li>
          </ul>
        </p>

       <h3 class="w3-text-teal">Post-training and applications</h3>
        <p>
          <ul>
             <li>
              Activity 7: Visit <a href="https://tiktokenizer.vercel.app/?model=gpt-3.5-turbo" target="new">TikTokenizer</a>, select an "insturct" model like gpt-3.5-turbo. Evaluate the tokens in the "imaginary monologue" and their structure. Despite looking like a conversation, everything processed by the model is still a one-dimensional sequence of tokens.
            </li>
          </ul>
         </p>
      <h3 class="w3-text-teal">Language models limitations and mitigations</h3>
        <p>
          <ul>
             <li>
              Activity 8: Visit the <a href="https://huggingface.co/playground" target="new">HuggingFace Playground</a> and load a small model. For example, tibiae falcon-7B-instruct or teknium OpenHermes-2.5-Mistral-7B. Ask about a person that does not exist and resample multiple time an answer. Ask about the outcome of recent events, such as a recent election or sports event. Repeat the same questions in <a href="https://chatgpt.com/" target="new">ChatGPT</a>. What's the difference? Why is it happening?
            </li>
             <li>
              Activity 9: Visit <a href="https://en.wikipedia.org/wiki/Gianluigi_Donnarumma" target="new">Wikipedia</a> and collect text about a recent event or person you are interested in. Paste the text in <a href="https://chatgpt.com/" target="new">ChatGPT</a> and have it create three questions about the information. Then go to <a href="https://huggingface.co/playground" target="new">HuggingFace Playground</a> and load a small model. For example, tibiae falcon-7B-instruct or teknium OpenHermes-2.5-Mistral-7B. Verify if the model knows the information you selected by asking each of the questions (resample a few times). What can you conclude from the exercise? (5 min).
            </li> 
             <li>
              Activity 10: Visit <a href="https://chatgpt.com/" target="new">ChatGPT</a> and have it discuss or summarize a topic the model should know very well (think about what would be such topic). Then try with something you know well, but the model is likely to have been barely exposed to (even though it should know because it predates the cutoff date). Now have it summarize the same topic after pasting content about it in the conversation.
            </li> 
          </ul>
         </p> 


    </div>
  </div>



  <footer id="myFooter">
    <div class="w3-container w3-theme-l2 w3-padding-32">
      <h4>MIBE: Information Systems for Managers</h4>
      <h4>2025 Edition</h4>
    </div>

    <div class="w3-container w3-theme-l1">
      <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></p>
    </div>
  </footer>

<!-- END MAIN -->
</div>

<script>
// Get the Sidebar
var mySidebar = document.getElementById("mySidebar");

// Get the DIV with overlay effect
var overlayBg = document.getElementById("myOverlay");

// Toggle between showing and hiding the sidebar, and add overlay effect
function w3_open() {
  if (mySidebar.style.display === 'block') {
    mySidebar.style.display = 'none';
    overlayBg.style.display = "none";
  } else {
    mySidebar.style.display = 'block';
    overlayBg.style.display = "block";
  }
}

// Close the sidebar with the close button
function w3_close() {
  mySidebar.style.display = "none";
  overlayBg.style.display = "none";
}
</script>

</body>
</html>
